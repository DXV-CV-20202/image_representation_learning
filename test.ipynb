{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\\Scripts\\python.exe\n",
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\\Scripts\\python.exe\n",
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip freeze\n",
    "!python -c \"import sys; print(sys.executable)\"\n",
    "import sys\n",
    "import os\n",
    "print(sys.executable)\n",
    "print(os.environ['VIRTUAL_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import IRDataset\n",
    "\n",
    "mean, std = 0.1307, 0.3081\n",
    "\n",
    "triplet_train_dataset = IRDataset(descriptor_path = './data/cifar-10/train.json',\n",
    "                                transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean,), (std,))\n",
    "                             ]))\n",
    "triplet_test_dataset = IRDataset(descriptor_path = './data/cifar-10/test.json',\n",
    "                                transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean,), (std,))\n",
    "                             ]))\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([3, 32, 32]), torch.Size([3, 32, 32]), torch.Size([3, 32, 32])]\n"
     ]
    }
   ],
   "source": [
    "print([i.shape for i in triplet_train_dataset.__getitem__(0)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import EmbeddingNet, EmbeddingNetL2, TripletNet, ResNetEmbedding\n",
    "from losses import TripletLoss\n",
    "from trainer import fit\n",
    "import torch.nn as nn\n",
    "\n",
    "embedding_net = ResNetEmbedding()\n",
    "triplet_net = TripletNet(embedding_net)\n",
    "\n",
    "if cuda:\n",
    "    triplet_net = triplet_net.cuda()\n",
    "\n",
    "margin = 1.0\n",
    "loss_fn = TripletLoss(margin)\n",
    "\n",
    "# def l_infinity(x1, x2):\n",
    "#     return torch.max(torch.abs(x1 - x2), dim=1).values\n",
    "# loss_fn = nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(triplet_net.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TripletNet(\n",
      "  (embedding_net): ResNetEmbedding(\n",
      "    (convnet): ResNetEncoder(\n",
      "      (gate): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (blocks): ModuleList(\n",
      "        (0): ResNetLayer(\n",
      "          (blocks): Sequential(\n",
      "            (0): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): None\n",
      "            )\n",
      "            (1): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): None\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResNetLayer(\n",
      "          (blocks): Sequential(\n",
      "            (0): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): Sequential(\n",
      "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): None\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ResNetLayer(\n",
      "          (blocks): Sequential(\n",
      "            (0): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): Sequential(\n",
      "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): None\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ResNetLayer(\n",
      "          (blocks): Sequential(\n",
      "            (0): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): Sequential(\n",
      "                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResNetBasicBlock(\n",
      "              (blocks): Sequential(\n",
      "                (0): Sequential(\n",
      "                  (conv): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (1): ReLU()\n",
      "                (2): Sequential(\n",
      "                  (conv): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (shortcut): None\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(triplet_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/50000 (0%)]\tLoss: 4.762521\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    fit(triplet_train_loader, triplet_test_loader, triplet_net, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    sample = triplet_train_dataset.__getitem__(22598)[0]\n",
    "# dataloader_iterator = iter(triplet_train_loader)\n",
    "# sample, _ = next(dataloader_iterator)\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = triplet_net.forward(sample[0], sample[1], sample[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# pos_dis = (e[0] - e[1]).pow(2).sum(1)\n",
    "# neg_dis = (e[0] - e[2]).pow(2).sum(1)\n",
    "# losses = F.relu(pos_dis - neg_dis + 1)\n",
    "# print(pos_dis, neg_dis, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet_net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_venv",
   "language": "python",
   "name": "ir_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "509592e7ae1caba26cc18676b1a1ddd67db5f8a856046ba2e6eda6c9f5e9e8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
